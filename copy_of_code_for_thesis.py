# -*- coding: utf-8 -*-
"""Copy of Code for thesis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L1tDDBvI0ORVrwS_5SFdDg4-tnlQnue3
"""

# important library import it
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.metrics import confusion_matrix as cm
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier

from time import perf_counter
import warnings
warnings.filterwarnings(action="ignore")

#load the data
df = pd.read_csv("/content/drive/MyDrive/datasets/House prices.csv")

#show csv data head
df.head()

# Separate features (input columns) and target variable
X = df.iloc[:, :-1]  # Select all columns except the last one
y = df.iloc[:, -1]   # Select the last column as the target variable



class_counts = df['Area'].value_counts()

# Calculate the percentage of each class
class_percentages = class_counts / class_counts.sum() * 100

# Filter classes with percentage greater than 15
filtered_classes = class_percentages[class_percentages>0.1]
line_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']
# Set the figure size
plt.figure(figsize=(10, 6))

# Plot the bar graph
ax = filtered_classes.plot(kind='bar', color=line_colors)

# Add labels and title
plt.xlabel('%age of Ransomware Family and Benign data')
plt.ylabel('Percentage')
plt.title('Dataset  distribution graph')

# Rotate x-axis labels
ax.tick_params(axis='x', rotation=45)

# Add percentage values on each bar
for i, v in enumerate(filtered_classes):
    ax.text(i, v + 1, f'{v:.1f}%', ha='center', color='black', fontweight='bold')

# Display the chart
plt.show()

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you have your DataFrame df already defined
# class_counts = df['family'].value_counts()

# Calculate the percentage of each class
class_percentages = class_counts / class_counts.sum() * 100

# Filter classes with percentage greater than 15
filtered_classes = class_percentages[class_percentages > 0.1]

# Set the figure size
plt.figure(figsize=(10, 6))

# Choose a colormap
cmap = plt.get_cmap("tab10")  # You can choose a different colormap here

# Create a list of x values (class labels)
x_values = range(len(filtered_classes))

# Plot the line graph with colormap
for i, color in zip(x_values, cmap(np.linspace(0, 1, len(x_values)))):
    plt.plot(i, filtered_classes.iloc[i], marker='o', linestyle='-',
             markersize=8, linewidth=2, color=color)

# Set x-axis labels
plt.xticks(x_values, filtered_classes.index, rotation=45)

# Add labels and title
plt.xlabel('Ransomware Family')
plt.ylabel('%age of Ransomware Family and Benign data')
plt.title('Dataset Distribution Graph')

# Add percentage values on each data point
for i, v in enumerate(filtered_classes.values):
    plt.text(x_values[i], v + 1, f'{v:.1f}%', ha='center', color='black', fontweight='bold')

# Display the chart
plt.grid(True)
plt.show()

class_counts = df['family'].value_counts()
print(class_counts.unique())
print(class_counts.to_string())
print(X_test[:,1])

import matplotlib.pyplot as plt
import numpy as np

# Using the `value_counts()` function to count the number of occurrences of each value in the `Benign` column
value_counts = df['Benign'].value_counts()

# Set the figure size and create a 3D figure and axes
fig = plt.figure(figsize=(8, 6))
ax = fig.add_subplot(111, projection='3d')

# Generate 3D stacked bar plot
x = np.zeros(2)
y = np.arange(2)
z = value_counts.values

# Define colors for each bar
colors = ['orchid', 'salmon']

# Plot the 3D stacked bars
dx = dy = 0.8
dz = np.zeros_like(z)
for i, val in enumerate(value_counts):
    dz[i] = val
    ax.bar3d(x, y[i], np.zeros_like(val), dx, dy, dz[i], color=colors[i])

# Add labels and title
ax.set_xlabel('Categories')
ax.set_ylabel('')
ax.set_zlabel('Amount')
ax.set_title('Machine File Values')

# Set y-axis tick labels
ax.set_yticks(y)
ax.set_yticklabels(['Safe (1)', 'Unsafe (0)'])

# Add value labels on top of each bar
for xi, yi, zi in zip(x, y, z):
    ax.text(xi + dx / 2, yi + dy / 2, zi + 1, f'{zi}', ha='center', va='center',
            color='black', fontweight='bold')

# Adjust the view angle
ax.view_init(elev=30, azim=120)

# Display the chart
plt.show()

# Using the `value_counts()` function to count the number of occurrences of each value in the `Benign` column
# Using the `plot()` function with `kind='bar'` to create a bar plot of the value counts
# Setting the color of the bars using the `color` parameter
df.Benign.value_counts().plot(kind = 'bar', color = ['orchid', 'salmon'])
plt.title("Machine file values")
plt.xlabel("1 == Safe, 0 == Unsafe")
plt.ylabel("Amount")
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OrdinalEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score,confusion_matrix

# Load the dataset from CSV
dataset_path = "/content/drive/MyDrive/datasets/House prices.csv"
df = pd.read_csv(dataset_path)

# Extract features and labels from the dataset
X = df[['Year', 'VALUE']]  # Select the categorical columns
y = df['VALUE']

# Create and fit the Ordinal Encoder
encoder = OrdinalEncoder()
X_encoded = encoder.fit_transform(X)

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)

# Create a Random Forest model
random_forest = RandomForestClassifier(n_estimators=100, random_state=0)

# Fit the model on the training data
random_forest.fit(X_train, y_train)

# Predict on the test data
RF_y_pred = random_forest.predict(X_test)

# Calculate accuracy
RF_accuracy = accuracy_score(y_test, RF_y_pred)
print('Accuracy:', RF_accuracy)

import matplotlib.pyplot as plt

# Assuming X_train and X_test contain the training and testing data points, respectively

# Create a scatter plot for training data
plt.scatter(X_train[:, 1], X_train[:, 2], c='b', label='Training Data')

# Create a scatter plot for testing data
plt.scatter(X_test[:, 1], X_test[:, 2], c='r', label='Testing Data')

# Adding labels and title
plt.xlabel('Ransomware Variant')
plt.ylabel('Benign')
plt.title('Scatter Plot of Training and Testing Data')

# Adding a legend
plt.legend()

# Displaying the plot
plt.grid(True)
plt.tight_layout()
plt.show()

# Create confusion matrix
cm_rf = confusion_matrix(y_test, RF_y_pred)

# Create a heatmap for the confusion matrix
plt.figure(figsize=(6, 4))
sns.heatmap(cm_rf, annot=True, fmt="d", cmap="Blues", cbar=True)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

from sklearn.metrics import precision_score, recall_score, f1_score
# Calculate precision, recall, and f1-score
precision = precision_score(y_test, RF_y_pred)
recall = recall_score(y_test, RF_y_pred)
f1 = f1_score(y_test, RF_y_pred)
print("precision is :",precision)
print("Recall is :",recall)
print("F1-Score is :",f1)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OrdinalEncoder
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset from CSV
dataset_path = "/content/drive/MyDrive/datasets/datasetfile_Balanced_ds1.csv"
df = pd.read_csv(dataset_path)

# Extract features and labels from the dataset
X = df[['Name', 'hash', 'family']]  # Select the categorical columns
y = df['Benign']

# Create and fit the Ordinal Encoder
encoder = OrdinalEncoder()
X_encoded = encoder.fit_transform(X)

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)

# Create a KNN model
k = 5  # Number of neighbors
knn = KNeighborsClassifier(n_neighbors=k)

# Fit the model on the training data
knn.fit(X_train, y_train)

# Predict on the test data
y_pred = knn.predict(X_test)

# Calculate accuracy
KNN_accuracy = accuracy_score(y_test, y_pred)
print('KNN Accuracy:', KNN_accuracy)

# Create confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Calculate precision, recall, and f1-score
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print('Precision:', precision)
print('Recall:', recall)
print('F1-Score:', f1)

# Create confusion matrix
cm_knn = confusion_matrix(y_test, y_pred)

# Create a heatmap for the confusion matrix
plt.figure(figsize=(6, 4))
sns.heatmap(cm_knn, annot=True, fmt="d", cmap="Blues", cbar=True)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix of KNN')
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OrdinalEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset from CSV
dataset_path = "/content/drive/MyDrive/datasets/datasetfile_Balanced_ds1.csv"
df = pd.read_csv(dataset_path)

# Extract features and labels from the dataset
X = df[['Name', 'hash', 'family']]  # Select the categorical columns
y = df['Benign']

# Create and fit the Ordinal Encoder
encoder = OrdinalEncoder()
X_encoded = encoder.fit_transform(X)

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)

# Create a Logistic Regression model
logreg = LogisticRegression()

# Fit the model on the training data
logreg.fit(X_train, y_train)

# Predict on the test data
y_pred = logreg.predict(X_test)

# Calculate accuracy
LR_accuracy = accuracy_score(y_test, y_pred)
print('Accuracy:', LR_accuracy)

# Create confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Calculate precision, recall, and f1-score
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print('Precision:', precision)
print('Recall:', recall)
print('F1-Score:', f1)

# Create confusion matrix
cm_lr = confusion_matrix(y_test, y_pred)

# Create a heatmap for the confusion matrix
plt.figure(figsize=(6, 4))
sns.heatmap(cm_lr, annot=True, fmt="d", cmap="Blues", cbar=True)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix of LR')
plt.show()

from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import cross_val_score, KFold
from numpy import mean, std

# create an instance of the model with desired hyperparameters
model = GaussianNB()  # no hyperparameters to set for GaussianNB
model.fit(X_train, y_train)
# Predict on the test data
y_pred = model.predict(X_test)

# Calculate accuracy
GNB_accuracy = accuracy_score(y_test, y_pred)
print('Accuracy:', GNB_accuracy)


# Create confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Calculate precision, recall, and f1-score
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print('Precision:', precision)
print('Recall:', recall)
print('F1-Score:', f1)

# Create confusion matrix
cm_gnb = confusion_matrix(y_test, y_pred)

# Create a heatmap for the confusion matrix
plt.figure(figsize=(6, 4))
sns.heatmap(cm_gnb, annot=True, fmt="d", cmap="Blues", cbar=True)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix of GNB')
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score
import numpy as np

# Create an instance of the MLP classifier with desired hyperparameters
mlp_model = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000)  # Example hyperparameters

# Train the MLP model on the training data
mlp_model.fit(X_train, y_train)

# Predict on the test data
y_pred_mlp = mlp_model.predict(X_test)

# Calculate accuracy
mlp_accuracy = accuracy_score(y_test, y_pred_mlp)
print('Accuracy:', mlp_accuracy)

# Calculate precision, recall, and f1-score
mlp_precision = precision_score(y_test, y_pred_mlp)
mlp_recall = recall_score(y_test, y_pred_mlp)
mlp_f1 = f1_score(y_test, y_pred_mlp)

print('Precision:', mlp_precision)
print('Recall:', mlp_recall)
print('F1-Score:', mlp_f1)

# Create confusion matrix
cm_mlp = confusion_matrix(y_test, y_pred_mlp)

# Create a heatmap for the confusion matrix
plt.figure(figsize=(6, 4))
sns.heatmap(cm_mlp, annot=True, fmt="d", cmap="Blues", cbar=True)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix of MLP')
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score

# Create an instance of the GradientBoostingClassifier with desired hyperparameters
gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.2, max_depth=5, random_state=42)  # Example hyperparameters

# Train the GradientBoostingClassifier on the training data
gb_model.fit(X_train, y_train)

# Predict on the test data
y_pred_gb = gb_model.predict(X_test)

# Calculate accuracy
gb_accuracy = accuracy_score(y_test, y_pred_gb)
print('Accuracy:', gb_accuracy)

# Calculate precision, recall, and f1-score
gb_precision = precision_score(y_test, y_pred_gb)
gb_recall = recall_score(y_test, y_pred_gb)
gb_f1 = f1_score(y_test, y_pred_gb)

print('Precision:', gb_precision)
print('Recall:', gb_recall)
print('F1-Score:', gb_f1)

# Create confusion matrix
cm_gb = confusion_matrix(y_test, y_pred_gb)

# Create a heatmap for the confusion matrix
plt.figure(figsize=(6, 4))
sns.heatmap(cm_gb, annot=True, fmt="d", cmap="Blues", cbar=True)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix of GradientBoostingClassifier')
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import AdaBoostClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score

# Create an instance of the AdaBoostClassifier with desired hyperparameters
adaboost_model = AdaBoostClassifier(n_estimators=50, learning_rate=1.0, random_state=42)  # Example hyperparameters

# Train the AdaBoostClassifier on the training data
adaboost_model.fit(X_train, y_train)

# Predict on the test data
y_pred_adaboost = adaboost_model.predict(X_test)

# Calculate accuracy
adaboost_accuracy = accuracy_score(y_test, y_pred_adaboost)
print('Accuracy:', adaboost_accuracy)

# Calculate precision, recall, and f1-score
adaboost_precision = precision_score(y_test, y_pred_adaboost)
adaboost_recall = recall_score(y_test, y_pred_adaboost)
adaboost_f1 = f1_score(y_test, y_pred_adaboost)

print('Precision:', adaboost_precision)
print('Recall:', adaboost_recall)
print('F1-Score:', adaboost_f1)

# Create confusion matrix
cm_adaboost = confusion_matrix(y_test, y_pred_adaboost)

# Create a heatmap for the confusion matrix
plt.figure(figsize=(6, 4))
sns.heatmap(cm_adaboost, annot=True, fmt="d", cmap="Blues", cbar=True)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix of AdaBoostClassifier')
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score

# Create an instance of the DecisionTreeClassifier with desired hyperparameters
dt_model = DecisionTreeClassifier(max_depth=3, random_state=42)  # Example hyperparameters

# Train the DecisionTreeClassifier on the training data
dt_model.fit(X_train, y_train)

# Predict on the test data
y_pred_dt = dt_model.predict(X_test)

# Calculate accuracy
dt_accuracy = accuracy_score(y_test, y_pred_dt)
print('Accuracy:', dt_accuracy)

# Calculate precision, recall, and f1-score
dt_precision = precision_score(y_test, y_pred_dt)
dt_recall = recall_score(y_test, y_pred_dt)
dt_f1 = f1_score(y_test, y_pred_dt)

print('Precision:', dt_precision)
print('Recall:', dt_recall)
print('F1-Score:', dt_f1)

# Create confusion matrix
cm_dt = confusion_matrix(y_test, y_pred_dt)

# Create a heatmap for the confusion matrix
plt.figure(figsize=(6, 4))
sns.heatmap(cm_dt, annot=True, fmt="d", cmap="Blues", cbar=True)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix of DecisionTreeClassifier')
plt.show()

"""**Learning Curve of Decision Tree**"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import learning_curve

# Create an instance of the DecisionTreeClassifier with desired hyperparameters
dt_model = DecisionTreeClassifier(max_depth=3, random_state=42)  # Example hyperparameters

# Create a function to plot the learning curve
def plot_learning_curve(estimator, title, X, y, cv, n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 5)):
    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)

    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)

    plt.figure(figsize=(8, 6))
    plt.title(title)
    plt.xlabel("Training examples")
    plt.ylabel("Score")
    plt.grid()

    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color="r")
    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color="g")

    plt.plot(train_sizes, train_scores_mean, 'o-', color="r", label="Training score")
    plt.plot(train_sizes, test_scores_mean, 'o-', color="g", label="Cross-validation score")

    plt.legend(loc="best")

# Plot the learning curve
plot_learning_curve(dt_model, "Learning Curve (DecisionTreeClassifier)", X_train, y_train, cv=5, n_jobs=-1)
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score

# Create an instance of the SVC with desired hyperparameters
svc_model = SVC(kernel='linear', C=1.0, random_state=42)  # Example hyperparameters

# Train the SVC model on the training data
svc_model.fit(X_train, y_train)

# Predict on the test data
y_pred_svc = svc_model.predict(X_test)

# Calculate accuracy
svc_accuracy = accuracy_score(y_test, y_pred_svc)
print('Accuracy:', svc_accuracy)

# Calculate precision, recall, and f1-score
svc_precision = precision_score(y_test, y_pred_svc)
svc_recall = recall_score(y_test, y_pred_svc)
svc_f1 = f1_score(y_test, y_pred_svc)

print('Precision:', svc_precision)
print('Recall:', svc_recall)
print('F1-Score:', svc_f1)

# Create confusion matrix
cm_svc = confusion_matrix(y_test, y_pred_svc)

# Create a heatmap for the confusion matrix
plt.figure(figsize=(6, 4))
sns.heatmap(cm_svc, annot=True, fmt="d", cmap="Blues", cbar=True)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix of SVC')
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score

# Create an instance of the Gaussian Naive Bayes classifier
nb_model = GaussianNB()

# Train the Naive Bayes model on the training data
nb_model.fit(X_train, y_train)

# Predict on the test data
y_pred_nb = nb_model.predict(X_test)

# Calculate accuracy
nb_accuracy = accuracy_score(y_test, y_pred_nb)
print('Accuracy:', nb_accuracy)

# Calculate precision, recall, and f1-score
nb_precision = precision_score(y_test, y_pred_nb)
nb_recall = recall_score(y_test, y_pred_nb)
nb_f1 = f1_score(y_test, y_pred_nb)

print('Precision:', nb_precision)
print('Recall:', nb_recall)
print('F1-Score:', nb_f1)

# Create confusion matrix
cm_nb = confusion_matrix(y_test_nb, y_pred_nb)

# Create a heatmap for the confusion matrix
plt.figure(figsize=(6, 4))
sns.heatmap(cm_nb, annot=True, fmt="d", cmap="Blues", cbar=True)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix of Gaussian Naive Bayes')
plt.show()

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred_svc))

#PLot all algorithms accuracy
import matplotlib.pyplot as plt
# Create a list of algorithm names
algorithms = ['Random Forest', 'KNN', 'Logistic Regression', 'Gaussian Naive Bays','multi-layer perceptron', 'Gradient Boost','Ada Boost Algorithm','decision Tree', 'SUport Vector Machine']

# Create a list of accuracy scores
accuracy_scores = [RF_accuracy, KNN_accuracy, .92, .97, .96, .92, .98, .99, .91]
# Define a color palette with light shades
colors = ['#10055e', '#a15d99', '#2d4c76', '#2024ee', '#ba1d91', '#336e71', '#294408','#11055e', '#a16d99',]

# Plotting the bar graph with light colors
plt.figure(figsize=(10, 6))
bars = plt.bar(algorithms, accuracy_scores, color=colors)

# Adding labels and title
plt.xlabel('Algorithms')
plt.ylabel('Accuracy')
plt.title('Accuracy Scores  of Different Algorithms')

# Rotating x-axis labels for better visibility
plt.xticks(rotation=90)

# Adding percentage values on top of each bar
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width() / 2, height, f'{height:.2%}', ha='center', va='bottom')

# Displaying the plot
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
# Create a list of algorithm names
algorithms = ['Random Forest', 'KNN', 'Logistic Regression', 'Gaussian Naive Bayes', 'Multi-Layer Perceptron', 'Gradient Boost', 'AdaBoost', 'Decision Tree', 'Support Vector Machine']

# Create a list of accuracy scores
accuracy_scores = [RF_accuracy, KNN_accuracy, .92, .97, .96, .92, .98, .99, .91]

# Define a color palette with light shades
colors = ['#10055e', '#a15d99', '#2d4c76', '#2024ee', '#ba1d91', '#336e71', '#294408', '#11055e', '#a16d99']

# Create a figure and axis
plt.figure(figsize=(10, 6))
plt.plot(algorithms, accuracy_scores, marker='o', linestyle='-', color='c', linewidth=2, markersize=8)

# Adding labels and title
plt.xlabel('Algorithms')
plt.ylabel('Accuracy')
plt.title('Accuracy Scores of Different Algorithms')

# Rotating x-axis labels for better visibility
plt.xticks(rotation=45)

# Adding percentage values next to data points
for i, score in enumerate(accuracy_scores):
    plt.text(algorithms[i], score, f'{score:.2%}', ha='center', va='bottom')

# Displaying the plot
plt.grid(True)
plt.tight_layout()
plt.show()

import numpy as np

# Sum all individual confusion matrices
combined_cm = cm_svc + cm_dt + cm_adaboost + cm_gb + cm_mlp + cm_gnb + cm_lr + cm_knn + cm_rf

# Create a heatmap for the combined confusion matrix
plt.figure(figsize=(6, 6))
sns.heatmap(combined_cm, annot=True, fmt="d", cmap="Blues", cbar=True)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Combined Confusion Matrix')
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import learning_curve
from sklearn.metrics import roc_auc_score, roc_curve, auc

# Load the dataset from CSV
dataset_path = "/content/drive/MyDrive/datasets/datasetfile_Balanced_ds1.csv"
df = pd.read_csv(dataset_path)

# Extract features and labels from the dataset
X = df[['Name', 'hash', 'family']]  # Select the categorical columns
y = df['Benign']

# Create and fit the Ordinal Encoder
encoder = OrdinalEncoder()
X_encoded = encoder.fit_transform(X)

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)

# Create a Random Forest model
random_forest = RandomForestClassifier(n_estimators=100, random_state=0)

# Initialize an array to store AUC scores
auc_scores = []

# Create a learning curve function
def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=1,
                        train_sizes=np.linspace(0.1, 1.0, 5)):
    plt.figure()
    plt.title(title)
    if ylim is not None:
        plt.ylim(*ylim)
    plt.xlabel("Training examples")
    plt.ylabel("AUC")
    train_sizes, train_scores, test_scores = learning_curve(
        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring='roc_auc')
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)
    plt.grid()

    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,
                     train_scores_mean + train_scores_std, alpha=0.1,
                     color="r")
    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,
                     test_scores_mean + test_scores_std, alpha=0.1, color="g")
    plt.plot(train_sizes, train_scores_mean, 'o-', color="r",
             label="Training AUC")
    plt.plot(train_sizes, test_scores_mean, 'o-', color="g",
             label="Cross-validation AUC")

    plt.legend(loc="best")
    return plt

# Plot the learning curve
plot_learning_curve(random_forest, "Learning Curve FOR-Cross Validation and Training AUC ", X_train, y_train, cv=5)

# Fit the model on the training data
random_forest.fit(X_train, y_train)

# Predict on the test data
RF_y_pred = random_forest.predict(X_test)

# Calculate AUC
RF_auc = roc_auc_score(y_test, RF_y_pred)
print('AUC:', RF_auc)

plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, learning_curve
from sklearn.preprocessing import OrdinalEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, auc

# Load the dataset from CSV
dataset_path = "/content/drive/MyDrive/datasets/datasetfile_Balanced_ds1.csv"
df = pd.read_csv(dataset_path)

# Extract features and labels from the dataset
X = df[['Name', 'hash', 'family']]  # Select the categorical columns
y = df['Benign']

# Create and fit the Ordinal Encoder
encoder = OrdinalEncoder()
X_encoded = encoder.fit_transform(X)

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)

# Create a Random Forest model
random_forest = RandomForestClassifier(n_estimators=100, random_state=0)

# Initialize an array to store AUC scores
auc_scores = []

# Create a learning curve function
def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=1,
                        train_sizes=np.linspace(0.1, 1.0, 5)):
    plt.figure()
    plt.title(title)
    if ylim is not None:
        plt.ylim(*ylim)
    plt.xlabel("Training examples")
    plt.ylabel("AUC")
    train_sizes, train_scores, test_scores = learning_curve(
        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring='roc_auc')
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)
    plt.grid()

    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,
                     train_scores_mean + train_scores_std, alpha=0.1,
                     color="r")
    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,
                     test_scores_mean + test_scores_std, alpha=0.1, color="g")
    plt.plot(train_sizes, train_scores_mean, 'o-', color="r",
             label="Training AUC")
    plt.plot(train_sizes, test_scores_mean, 'o-', color="g",
             label="Cross-validation AUC")

    plt.legend(loc="best")
    return plt

# Plot the learning curve
plot_learning_curve(random_forest, "Learning Curve", X_train, y_train, cv=5)

# Fit the model on the training data
random_forest.fit(X_train, y_train)

# Predict on the test data
RF_y_pred = random_forest.predict(X_test)

# Calculate AUC
RF_auc = roc_auc_score(y_test, RF_y_pred)
print('AUC:', RF_auc)

# Generate ROC curve
fpr, tpr, thresholds = roc_curve(y_test, random_forest.predict_proba(X_test)[:, 1])
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()

import matplotlib.pyplot as plt

# Create a list of algorithm names
algorithms = ['Random Forest', 'KNN', 'Logistic Regression', 'Gaussian Naive Bayes', 'Multi-Layer Perceptron', 'Gradient Boost', 'AdaBoost', 'Decision Tree', 'Support Vector Machine']

# Create a list of accuracy scores for each algorithm
accuracy_scores = [RF_accuracy, KNN_accuracy, 0.92, 0.97, 0.96, 0.92, 0.98, 0.99, 0.91]

# Define a color palette with different colors for each line
colors = ['#10055e', '#a15d99', '#2d4c76', '#2024ee', '#ba1d91', '#336e71', '#294408', '#11055e', '#a16d99']

# Create a figure and axis
plt.figure(figsize=(10, 6))

# Iterate through algorithms and plot lines with different colors
for i, algorithm in enumerate(algorithms):
    plt.plot([algorithm], [accuracy_scores[i]], marker='o', linestyle='-', color=colors[i], label=algorithm, markersize=8, linewidth=2)

# Adding labels and title
plt.xlabel('Algorithms')
plt.ylabel('Accuracy')
plt.title('Accuracy Scores of Different Algorithms')

# Rotating x-axis labels for better visibility
plt.xticks(rotation=45)

# Adding percentage values next to data points
for i, score in enumerate(accuracy_scores):
    plt.text(algorithms[i], score, f'{score:.2%}', ha='center', va='bottom')

# Displaying the plot with a legend
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

# Create a list of algorithm names
algorithms = ['Random Forest', 'KNN', 'Logistic Regression', 'Gaussian Naive Bayes', 'Multi-Layer Perceptron', 'Gradient Boost', 'AdaBoost', 'Decision Tree', 'Support Vector Machine']

# Create a list of accuracy scores for each algorithm
accuracy_scores = [RF_accuracy, KNN_accuracy, 0.92, 0.97, 0.96, 0.92, 0.98, 0.99, 0.91]

# Define a color palette with different colors for each point
colors = ['#10055e', '#a15d99', '#2d4c76', '#2024ee', '#ba1d91', '#336e71', '#294408', '#11055e', '#a16d99']

# Create a figure and axis
plt.figure(figsize=(10, 6))

# Create a scatter plot
plt.scatter(algorithms, accuracy_scores, color=colors, marker='o', s=100)

# Adding labels and title
plt.xlabel('Algorithms')
plt.ylabel('Accuracy')
plt.title('Accuracy Scores of Different Algorithms (Scatter Plot)')

# Rotating x-axis labels for better visibility
plt.xticks(rotation=45)

# Adding percentage values next to data points
for i, score in enumerate(accuracy_scores):
    plt.text(algorithms[i], score, f'{score:.2%}', ha='center', va='bottom')

# Displaying the plot
plt.grid(True)
plt.tight_layout()
plt.show()

